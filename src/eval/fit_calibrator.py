#!/usr/bin/env python
"""
fit_calibrator.py
==================

Command‑line utility for training an isotonic regression calibrator on
historical prediction data.  The calibrator is designed to correct bias in
model probabilities for NBA win predictions.  It reads a CSV file (typically
``backtest_per_game.csv`` generated by ``src/eval/backtest.py``), identifies
the model probability and actual outcome columns, fits an isotonic
regression, and saves the resulting calibrator to disk.

Usage example:

    python -m fit_calibrator \
        --per_game outputs/backtest_per_game.csv \
        --out models/calibrator.joblib

Optional flags allow overriding the column used for the model probability
(``--model-prob-col``) and the column containing the true outcome
(``--result-col``).  If unspecified, the script will auto‑detect these
columns using ``detect_columns()`` from ``src/eval/roi_analysis.py``.
"""

from __future__ import annotations

import argparse
import os
import pandas as pd

from src.model.calibration import fit_isotonic, save_calibrator


def _auto_detect_columns(df: pd.DataFrame) -> tuple[str, str]:
    """Attempt to infer model probability and result columns from a DataFrame.

    Looks for reasonable defaults such as ``home_win_prob`` and
    ``home_win_actual``.  If multiple candidate columns exist, the first
    match is used.

    Args:
        df: DataFrame loaded from per‑game backtest output.

    Returns:
        Tuple of (model_probability_column, result_column).
    """
    prob_candidates = [
        "home_win_prob", "home_win_prob_market", "home_win_prob_model", "home_prob_model"
    ]
    result_candidates = ["home_win_actual", "home_win", "home_win_result"]

    model_prob_col = next((c for c in prob_candidates if c in df.columns), None)
    result_col = next((c for c in result_candidates if c in df.columns), None)

    if model_prob_col is None or result_col is None:
        raise RuntimeError(
            "Could not auto‑detect probability or result column. Specify via --model-prob-col and --result-col."
        )
    return model_prob_col, result_col


def main() -> None:
    parser = argparse.ArgumentParser(description="Fit an isotonic calibrator for win probabilities.")
    parser.add_argument(
        "--per_game", required=True, help="CSV file with per‑game predictions and results (e.g. backtest_per_game.csv)"
    )
    parser.add_argument(
        "--out", required=True, help="Output path for the fitted calibrator (.joblib)"
    )
    parser.add_argument(
        "--model-prob-col", default=None, help="Name of the model probability column (auto‑detect if omitted)"
    )
    parser.add_argument(
        "--result-col", default=None, help="Name of the actual result column (auto‑detect if omitted)"
    )
    args = parser.parse_args()

    if not os.path.exists(args.per_game):
        raise FileNotFoundError(f"Input per_game file not found: {args.per_game}")

    df = pd.read_csv(args.per_game)

    model_col = args.model_prob_col
    result_col = args.result_col

    # Auto detect if needed
    if model_col is None or result_col is None:
        detected_model, detected_result = _auto_detect_columns(df)
        model_col = model_col or detected_model
        result_col = result_col or detected_result
        print(f"[fit_calibrator] Auto‑detected model_prob_col='{model_col}', result_col='{result_col}'")

    # Extract and coerce
    y_pred = pd.to_numeric(df[model_col], errors="coerce")
    y_true_raw = df[result_col]

    # Normalize actual outcomes to 0/1
    if y_true_raw.dtype == bool:
        y_true = y_true_raw.astype(int)
    else:
        y_true = pd.to_numeric(y_true_raw, errors="coerce")

    # Fit calibrator
    calibrator = fit_isotonic(y_true.values, y_pred.values)

    # Save
    os.makedirs(os.path.dirname(args.out), exist_ok=True)
    save_calibrator(calibrator, args.out)
    print(
        f"[fit_calibrator] Fitted isotonic calibrator on {len(y_true.dropna())} samples and saved to {args.out}"
    )


if __name__ == "__main__":
    main()

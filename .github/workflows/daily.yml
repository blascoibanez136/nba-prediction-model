name: Daily NBA run

on:
  workflow_dispatch: {}
  schedule:
    - cron: "0 13 * * *"  # 13:00 UTC every day

jobs:
  run-nba-pipeline:
    runs-on: ubuntu-latest

    env:
      # Leave RUN_DATE empty to use today's date. Set to YYYY-MM-DD to backfill.
      RUN_DATE: ""
      # Edge-picker thresholds (tune as desired)
      EDGE_THRESHOLD: "1.5"
      KELLY_THRESHOLD: "0.01"
      BOOK_WHITELIST: "draftkings,fanduel"

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install pandas numpy joblib requests pyyaml scikit-learn lightgbm

      - name: Ensure runtime folders
        run: |
          mkdir -p data/_snapshots
          mkdir -p outputs

      # ===================== Odds snapshots =====================
      - name: Save OPEN odds snapshot
        env:
          PYTHONPATH: .
          ODDS_API_KEY: ${{ secrets.ODDS_API_KEY }}
          SNAPSHOT_KIND: open
        run: |
          python src/ingest/odds_snapshots.py

      - name: Save MID odds snapshot
        env:
          PYTHONPATH: .
          ODDS_API_KEY: ${{ secrets.ODDS_API_KEY }}
          SNAPSHOT_KIND: mid
        run: |
          python src/ingest/odds_snapshots.py

      - name: Save CLOSE odds snapshot
        env:
          PYTHONPATH: .
          ODDS_API_KEY: ${{ secrets.ODDS_API_KEY }}
          SNAPSHOT_KIND: close
        run: |
          python src/ingest/odds_snapshots.py
      # ==========================================================

      - name: Build odds movement & dispersion
        env:
          PYTHONPATH: .
        run: |
          python - << 'PY'
          import os, glob
          import pandas as pd
          from src.ingest.odds_snapshots import compute_movement, compute_dispersion

          snap_dir = "data/_snapshots"
          os.makedirs("outputs", exist_ok=True)

          snaps = sorted(glob.glob(os.path.join(snap_dir, "*.csv")))
          latest_open = None
          latest_close = None

          for p in snaps:
            base = os.path.basename(p)
            if base.startswith("open_"):
              latest_open = p
            elif base.startswith("close_"):
              latest_close = p

          if latest_open and latest_close:
            movement = compute_movement(latest_open, latest_close)
            movement.to_csv("outputs/odds_movement_latest.csv", index=False)

            close_df = pd.read_csv(latest_close)
            disp = compute_dispersion(close_df)
            disp.to_csv("outputs/odds_dispersion_latest.csv", index=False)

            print("wrote odds_movement_latest.csv and odds_dispersion_latest.csv")
          else:
            print("No open/close pair found; skipping odds feature build.")
          PY

      - name: Run daily pipeline (schedule + predictions + picks)
        env:
          PYTHONPATH: .
          BALLDONTLIE_API_KEY: ${{ secrets.BALLDONTLIE_API_KEY }}
          ODDS_API_KEY: ${{ secrets.ODDS_API_KEY }}
          RUN_DATE: ${{ env.RUN_DATE }}
          EDGE_THRESHOLD: ${{ env.EDGE_THRESHOLD }}
          KELLY_THRESHOLD: ${{ env.KELLY_THRESHOLD }}
          BOOK_WHITELIST: ${{ env.BOOK_WHITELIST }}
        run: |
          python run_daily.py

      - name: Evaluate + Calibrate
        env:
          PYTHONPATH: .
          RUN_DATE: ${{ env.RUN_DATE }}
          RAPIDAPI_KEY: ${{ secrets.RAPIDAPI_KEY }}
        run: |
          python src/eval/calibration.py

      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: nba-run
          path: |
            outputs/
            run_summary.md
            calibration_report.html
            picks_report.html
            outputs/picks_*.csv

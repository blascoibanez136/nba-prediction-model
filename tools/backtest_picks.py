"""
Backtest picks generated by historical_picks_runner.

Joins picks CSVs against historical results and optional market snapshots,
then computes realized performance (ROI, hit rate, etc).

CRITICAL:
- Must never silently succeed on empty data
- Must never assume fixed score column names
"""

from __future__ import annotations

import argparse
import json
import logging
from pathlib import Path
from typing import Tuple

import pandas as pd

logger = logging.getLogger(__name__)


# ---------------------------------------------------------------------
# Utilities
# ---------------------------------------------------------------------

def _find_score_cols(df: pd.DataFrame) -> Tuple[str, str]:
    """
    Detect home/away score columns dynamically.

    Mirrors src/eval/backtest.py behavior.
    """
    candidates = [
        ("home_score", "away_score"),
        ("home_points", "away_points"),
        ("pts_home", "pts_away"),
        ("home_team_score", "away_team_score"),
    ]
    for h, a in candidates:
        if h in df.columns and a in df.columns:
            return h, a

    raise RuntimeError(
        "[picks_backtest] Could not find home/away score columns in history. "
        f"Available columns: {list(df.columns)}"
    )


def _load_csvs(dir_path: Path, pattern: str) -> pd.DataFrame:
    files = sorted(dir_path.glob(pattern))
    if not files:
        raise RuntimeError(f"[picks_backtest] No picks files matched: {dir_path}/{pattern}")

    dfs = []
    for f in files:
        df = pd.read_csv(f)
        if not df.empty:
            df["_source_file"] = f.name
            dfs.append(df)

    if not dfs:
        raise RuntimeError("[picks_backtest] All picks files were empty")

    return pd.concat(dfs, ignore_index=True)


# ---------------------------------------------------------------------
# Core logic
# ---------------------------------------------------------------------

def backtest_picks(
    picks_df: pd.DataFrame,
    history_df: pd.DataFrame,
    snapshot_dir: Path | None,
    config: dict,
) -> Tuple[pd.DataFrame, dict]:

    if picks_df.empty:
        raise RuntimeError("[picks_backtest] picks_df is empty")

    required = {"merge_key", "bet_side", "odds"}
    missing = required - set(picks_df.columns)
    if missing:
        raise RuntimeError(f"[picks_backtest] Missing required pick columns: {sorted(missing)}")

    # Join to history
    joined = picks_df.merge(
        history_df,
        on="merge_key",
        how="left",
        validate="many_to_one",
        indicator=True,
    )

    audit = {
        "picks_rows": int(len(picks_df)),
        "joined_rows": int(len(joined)),
        "missing_history": int((joined["_merge"] != "both").sum()),
    }

    joined = joined[joined["_merge"] == "both"].drop(columns="_merge")

    if joined.empty:
        raise RuntimeError("[picks_backtest] All picks dropped after history join")

    # Resolve score columns SAFELY
    home_score_col, away_score_col = _find_score_cols(joined)

    joined["home_win"] = (
        joined[home_score_col] > joined[away_score_col]
    ).astype(float)

    # Resolve bet outcome
    def _resolve_result(row):
        if row["bet_side"] == "HOME":
            return row["home_win"]
        if row["bet_side"] == "AWAY":
            return 1.0 - row["home_win"]
        return None

    joined["result"] = joined.apply(_resolve_result, axis=1)

    # Payout model (decimal odds assumed)
    stake = float(config.get("stake", 1.0))
    joined["stake"] = stake
    joined["pnl"] = joined.apply(
        lambda r: (r["odds"] - 1.0) * stake if r["result"] == 1.0 else -stake,
        axis=1,
    )

    return joined, audit


# ---------------------------------------------------------------------
# CLI
# ---------------------------------------------------------------------

def main() -> int:
    ap = argparse.ArgumentParser()
    ap.add_argument("--picks-dir", required=True)
    ap.add_argument("--pattern", default="picks_*.csv")
    ap.add_argument("--history", required=True)
    ap.add_argument("--snapshot-dir", default=None)
    ap.add_argument("--out-dir", required=True)
    ap.add_argument("--stake", type=float, default=1.0)
    args = ap.parse_args()

    picks_dir = Path(args.picks_dir)
    out_dir = Path(args.out_dir)
    out_dir.mkdir(parents=True, exist_ok=True)

    picks_df = _load_csvs(picks_dir, args.pattern)
    history_df = pd.read_csv(args.history)

    config = {"stake": args.stake}

    joined, audit = backtest_picks(
        picks_df,
        history_df,
        snapshot_dir=Path(args.snapshot_dir) if args.snapshot_dir else None,
        config=config,
    )

    joined_path = out_dir / "picks_backtest.csv"
    audit_path = out_dir / "picks_backtest_audit.json"
    summary_path = out_dir / "picks_backtest_summary.csv"

    joined.to_csv(joined_path, index=False)
    audit_path.write_text(json.dumps(audit, indent=2))

    summary = pd.DataFrame(
        [{
            "bets": len(joined),
            "wins": int((joined["result"] == 1.0).sum()),
            "losses": int((joined["result"] == 0.0).sum()),
            "roi": joined["pnl"].sum() / joined["stake"].sum(),
            "total_pnl": joined["pnl"].sum(),
        }]
    )
    summary.to_csv(summary_path, index=False)

    logger.info("[picks_backtest] wrote %s", joined_path)
    logger.info("[picks_backtest] wrote %s", summary_path)
    logger.info("[picks_backtest] wrote %s", audit_path)

    return 0


if __name__ == "__main__":
    raise SystemExit(main())
